\section{Related Work}
As we know word embeddings, like in word2vec \cite{word2vec}, have brought a drastic change in the lingusitics community. It is mainly because every early approach to NLP required a knowledge of linguistics and it was assumed that a person knowing more languages would intuitively know more about doing efficient natural language processing. But word embeddings came and just changed everything. Not only we need to have any sort of lingusitic knowledge to perform NLP applications, but we can just represent any word of any language as a very high dimensional vector. Since these embeddings are of a very high dimension, visualizing these embeddings becomes hard since we cannot visualize anything using more than 3 dimensions. \\

Fortunately, there have been many ways of visualizing word embeddings, mainly by using the principles of dimensitionality reuduction and projecting these embeddings onto a 2 Dimensional space. Two very prominent techniques to do that are Principal Component Analysis (PCA) \cite{pca} and the more recent t-SNE \cite{t-sne}. Both of these techniques bring in potential problems that make it for the user hard to understand anything from these visualizations. For example, when the number of data points become extremely large, the visualization gets largely cluttered. The visualization of word embeddings using t-SNE is shown in Figure~\ref{fig:t_sne}. Not only that, but t-SNE is also known to have counter-intuitive features such as ``cluster sizes mean nothing''\footnote{https://distill.pub/2016/misread-tsne/}). One possible solution to avoid the visual cluttering is to enable user interaction and move around the words. \\ 

One notable work on adding interaction on top of dimensionality reduction methods to avoid the visualization cluttering is Tensorboard (Figure~\ref{fig:tensorboard}) \cite{tensorboard_viz}. 
Tensorboard has multiple user-friendly features to enable exploratory analysis on word embeddings by (1) searching for words, and (2) clickabble and draggable 3D space. 
However, there are many downsides of a Tensorboard-based visualization. One is the lack of summarization and collapsing data points, and also that the user does not have any idea of how to make sense of this kind of a data, because all the user can see is a large collection of points distributed in the 3D space. So when we started this project, we understood that projecting embeddings on a low-dimensional space and just adding basic interaction will not help the user understand the semantics of the word embedding visualization. \\
   
Therefore in our project, we focus on adding an efficient data collapsing feature, achieved by an efficient k-means clustering algorithm, and also adding an appropriate feature to make the user understand the semantics of these word embeddings, which we achieve by using emojis. 
